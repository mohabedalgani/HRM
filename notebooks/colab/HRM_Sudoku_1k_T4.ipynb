{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß© HRM Sudoku-Extreme 1 k Demo\n",
        "**Google Colab PRO (High-RAM) + T4 GPU ‚Äì single-GPU reproduction of the paper‚Äôs 1 k-shot run.**  \n",
        "Runtime: ~50 min on A100-high-ram, ~55 min on T4-high-ram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 0Ô∏è‚É£ Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 1Ô∏è‚É£ One-liner installs (CUDA 12.6 + PyTorch 2.4 + Flash-Attn 2)\n",
        "import os, subprocess, sys\n",
        "def run(cmd): subprocess.run(cmd, shell=True, check=True)\n",
        "\n",
        "# PyTorch 2.4 + CUDA 12.6 wheels\n",
        "run(\"pip install torch==2.4.0+cu126 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\")\n",
        "\n",
        "# Ninja + setuptools for compilation\n",
        "run(\"pip install packaging ninja wheel setuptools setuptools-scm\")\n",
        "\n",
        "# Flash-Attention 2 (works on T4/A100)\n",
        "run(\"pip install flash-attn --no-build-isolation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 2Ô∏è‚É£ Clone HRM repo + submodules\n",
        "run(\"git clone --recursive https://github.com/sapientinc/HRM.git\")\n",
        "%cd HRM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 3Ô∏è‚É£ Python deps\n",
        "run(\"pip install -r requirements.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Build the Sudoku-Extreme 1 k dataset  \n",
        "This is exactly the same as the paper‚Äôs `subsample-size 1000 --num-aug 1000`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 4Ô∏è‚É£ Build dataset (~30 s)\n",
        "run(\"python dataset/build_sudoku_dataset.py --output-dir data/sudoku-extreme-1k-aug-1000 --subsample-size 1000 --num-aug 1000\")\n",
        "!ls data/sudoku-extreme-1k-aug-1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Train (single GPU, small batch)\n",
        "We halve the batch size (192 instead of 384) to fit T4 16 GB.  \n",
        "The run will auto-log to Weights & Biases if you‚Äôre logged in (`wandb login`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 5Ô∏è‚É£ Launch training\n",
        "cmd = \"\"\"\n",
        "OMP_NUM_THREADS=8 python pretrain.py \\\n",
        "  data_path=data/sudoku-extreme-1k-aug-1000 \\\n",
        "  epochs=2000 \\\n",
        "  eval_interval=500 \\\n",
        "  global_batch_size=192 \\\n",
        "  lr=7e-5 \\\n",
        "  puzzle_emb_lr=7e-5 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  wandb_project=\"hrm-colab-sudoku1k\"\n",
        "\"\"\"\n",
        "run(cmd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Evaluate\n",
        "After training finishes (~step 1500) we run the built-in exact-accuracy evaluator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 6Ô∏è‚É£ Evaluate last checkpoint\n",
        "ckpt_path = !ls -t checkpoints/*/ckpt.pt | head -1\n",
        "ckpt_path = ckpt_path[0]\n",
        "print(\"Evaluating\", ckpt_path)\n",
        "run(f\"python evaluate.py checkpoint={ckpt_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Show one solved grid\n",
        "We decode the first validation sample back to a human-readable Sudoku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 7Ô∏è‚É£ Pretty print a solved puzzle\n",
        "from src.utils.sudoku import Sudoku\n",
        "import torch\n",
        "\n",
        "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "model = ckpt[\"model\"]\n",
        "model.eval()\n",
        "\n",
        "from src.data.sudoku_dataset import SudokuDataset\n",
        "ds = SudokuDataset(\"data/sudoku-extreme-1k-aug-1000\", split=\"val\")\n",
        "sample = ds[0]\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(sample[\"input_ids\"].unsqueeze(0).cuda())\n",
        "pred = logits.argmax(-1).cpu()\n",
        "\n",
        "print(\"Input puzzle:\\n\", Sudoku(sample[\"input_ids\"].view(9,9)).grid)\n",
        "print(\"Model solution:\\n\", Sudoku(pred.view(9,9)).grid)\n",
        "print(\"Target:\\n\", Sudoku(sample[\"target\"].view(9,9)).grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ Save checkpoint to Drive (optional)\n",
        "Mount your Drive and copy the 120 MB checkpoint so others can load it instantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 8Ô∏è‚É£ Mount Drive & save\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/hrm_sudoku1k_t4\"\n",
        "run(f\"mkdir -p {save_dir}\")\n",
        "run(f\"cp -r checkpoints {save_dir}\")\n",
        "print(\"Checkpoint saved to\", save_dir)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "standard",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}