{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTw8a8fKz36D"
      },
      "source": [
        "# üß© HRM Sudoku-Extreme 1 k Demo\n",
        "**Google Colab PRO (High-RAM) + T4 GPU ‚Äì single-GPU reproduction of the paper‚Äôs 1 k-shot run.**  \n",
        "Runtime: ~50 min on A100-high-ram, ~55 min on T4-high-ram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eF-0O0Bz36L",
        "outputId": "b47177e5-1253-41b9-b3a7-d4c717912aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Aug  2 12:45:05 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@title 0Ô∏è‚É£ Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jJZYWmbGz36N"
      },
      "outputs": [],
      "source": [
        "#@title 1Ô∏è‚É£ One-liner installs (CUDA 12.6 + PyTorch 2.4 + Flash-Attn 2)\n",
        "import os, subprocess, sys\n",
        "def run(cmd):\n",
        "    try:\n",
        "        subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"Command failed:\", e.cmd)\n",
        "        print(\"Return code:\", e.returncode)\n",
        "        print(\"Output (stdout):\", e.stdout)\n",
        "        print(\"Error (stderr):\", e.stderr)\n",
        "        raise # Re-raise the exception after printing\n",
        "\n",
        "# PyTorch 2.7 + CUDA 12.6 wheels\n",
        "run(\"pip install torch==2.7.0+cu126 --index-url https://download.pytorch.org/whl/cu126 --no-cache-dir --force-reinstall\")\n",
        "run(\"pip install torchvision==0.22.1+cu126 --index-url https://download.pytorch.org/whl/cu126 --no-cache-dir --force-reinstall\")\n",
        "run(\"pip install torchaudio==2.7.0+cu126 --index-url https://download.pytorch.org/whl/cu126 --no-cache-dir --force-reinstall\")\n",
        "\n",
        "\n",
        "# Ninja + setuptools for compilation\n",
        "run(\"pip install packaging ninja wheel setuptools setuptools-scm\")\n",
        "\n",
        "# Flash-Attention 2 (works on T4/A100)\n",
        "run(\"pip install flash-attn --no-build-isolation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "KaDXj4aDz36O",
        "outputId": "2e0f6682-afb7-479d-91e0-798eb82c4fd7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-2755294961.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2755294961.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    git config --global url.\"https://github.com/\".insteadOf \"git@github.com:\"\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# already inside /content/HRM\n",
        "git config --global url.\"https://github.com/\".insteadOf \"git@github.com:\"\n",
        "git submodule update --init --recursive --depth=1 || true   # ignore ARC failures"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l dataset/"
      ],
      "metadata": {
        "id": "D8JTH8eaFXrk",
        "outputId": "e7894816-147a-4f90-f7a2-38a9ee4e70c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 36\n",
            "-rw-r--r-- 1 root root 10084 Aug  2 13:59 build_arc_dataset.py\n",
            "-rw-r--r-- 1 root root  4461 Aug  2 13:59 build_maze_dataset.py\n",
            "-rw-r--r-- 1 root root  5753 Aug  2 13:59 build_sudoku_dataset.py\n",
            "-rw-r--r-- 1 root root  1381 Aug  2 13:59 common.py\n",
            "drwxr-xr-x 5 root root  4096 Aug  2 13:59 raw-data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNT4J3ATz36P",
        "outputId": "8a1b20ec-a005-433f-d4fd-b84152e8bc58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/HRM/dataset/build_sudoku_dataset.py\", line 7, in <module>\n",
            "    from argdantic import ArgParser\n",
            "ModuleNotFoundError: No module named 'argdantic'\n"
          ]
        }
      ],
      "source": [
        "!python dataset/build_sudoku_dataset.py \\\n",
        "  --output-dir data/sudoku-extreme-1k-aug-1000 \\\n",
        "  --subsample-size 1000 \\\n",
        "  --num-aug 1000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt   # already done upstream? safe to re-run"
      ],
      "metadata": {
        "id": "4pyW05FKFn4c",
        "outputId": "c4e15b0d-3647-427d-e801-6ee8ff26b5d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.7.0+cu126)\n",
            "Collecting adam-atan2 (from -r requirements.txt (line 2))\n",
            "  Downloading adam_atan2-0.0.3.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
            "Collecting coolname (from -r requirements.txt (line 5))\n",
            "  Downloading coolname-2.2.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.11.7)\n",
            "Collecting argdantic (from -r requirements.txt (line 7))\n",
            "  Downloading argdantic-1.3.3-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.21.0)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.3.0)\n",
            "Collecting hydra-core (from -r requirements.txt (line 10))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch->-r requirements.txt (line 1)) (70.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 6)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 6)) (0.4.1)\n",
            "Collecting pydantic-settings<3,>=2.4.0 (from argdantic->-r requirements.txt (line 7))\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 8)) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 8)) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 8)) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 8)) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 8)) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 8)) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 8)) (2.33.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 9)) (4.9.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r requirements.txt (line 11)) (1.1.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8)) (4.0.12)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3,>=2.4.0->argdantic->-r requirements.txt (line 7))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8)) (5.0.2)\n",
            "Downloading coolname-2.2.0-py2.py3-none-any.whl (37 kB)\n",
            "Downloading argdantic-1.3.3-py2.py3-none-any.whl (26 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: adam-atan2\n",
            "  Building wheel for adam-atan2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adam-atan2: filename=adam_atan2-0.0.3-cp311-cp311-linux_x86_64.whl size=196238 sha256=a3cf4847712d8c8c94a462793a1eaf92e7c44a0b5ef079dd130ecdf46dbf6182\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/58/2a/9b3bd25c65b754ff4182332021a5ffff4fe68382acae55520f\n",
            "Successfully built adam-atan2\n",
            "Installing collected packages: coolname, adam-atan2, python-dotenv, hydra-core, pydantic-settings, argdantic\n",
            "Successfully installed adam-atan2-0.0.3 argdantic-1.3.3 coolname-2.2.0 hydra-core-1.3.2 pydantic-settings-2.10.1 python-dotenv-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQxBUdNPz36Q"
      },
      "source": [
        "## 4Ô∏è‚É£ Build the Sudoku-Extreme 1 k dataset  \n",
        "This is exactly the same as the paper‚Äôs `subsample-size 1000 --num-aug 1000`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLNx0XfRz36Q",
        "outputId": "4288c527-3f2b-4ff4-bb87-80078ee42794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "identifiers.json  test\ttrain\n"
          ]
        }
      ],
      "source": [
        "#@title 4Ô∏è‚É£ Build dataset (~30 s)\n",
        "run(\"python dataset/build_sudoku_dataset.py --output-dir data/sudoku-extreme-1k-aug-1000 --subsample-size 1000 --num-aug 1000\")\n",
        "!ls data/sudoku-extreme-1k-aug-1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABj5pP_-z36R"
      },
      "source": [
        "## 5Ô∏è‚É£ Train (single GPU, small batch)\n",
        "We halve the batch size (192 instead of 384) to fit T4 16 GB.  \n",
        "The run will auto-log to Weights & Biases if you‚Äôre logged in (`wandb login`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gALlWurYz36R",
        "outputId": "bde0411a-b4c1-4c97-b458-1950abdfc4bf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/HRM/pretrain.py\")"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.view('/content/HRM/pretrain.py')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/HRM\n",
        "python pretrain.py \\\n",
        "  data_path=data/sudoku-extreme-1k-aug-1000 \\\n",
        "  epochs=2000 \\\n",
        "  eval_interval=500 \\\n",
        "  global_batch_size=192 \\\n",
        "  lr=7e-5 \\\n",
        "  puzzle_emb_lr=7e-5 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0"
      ],
      "metadata": {
        "id": "AmIPf_BqIVtT",
        "outputId": "ed521958-ce18-47cc-a326-dd8bcb23de78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Rank 0, World Size 1]: Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10416 [00:00<?, ?it/s]W0802 14:16:56.370000 27561 torch/_inductor/utils.py:1250] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:2178: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "Error executing job with overrides: ['data_path=data/sudoku-extreme-1k-aug-1000', 'epochs=2000', 'eval_interval=500', 'global_batch_size=192', 'lr=7e-5', 'puzzle_emb_lr=7e-5', 'weight_decay=1.0', 'puzzle_emb_weight_decay=1.0']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/HRM/pretrain.py\", line 429, in launch\n",
            "    metrics = train_batch(config, train_state, batch, global_batch_size, rank=RANK, world_size=WORLD_SIZE)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRM/pretrain.py\", line 223, in train_batch\n",
            "    train_state.carry, loss, metrics, _, _ = train_state.model(carry=train_state.carry, batch=batch, return_keys=[])\n",
            "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 655, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRM/models/losses.py\", line 57, in forward\n",
            "    new_carry, outputs = self.model(**model_kwargs)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRM/models/hrm/hrm_act_v1.py\", line 249, in forward\n",
            "    new_inner_carry, logits, (q_halt_logits, q_continue_logits) = self.inner(new_inner_carry, new_current_data)\n",
            "                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRM/models/hrm/hrm_act_v1.py\", line 195, in forward\n",
            "    z_L = self.L_level(z_L, z_H + input_embeddings, **seq_info)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRM/models/hrm/hrm_act_v1.py\", line 97, in forward\n",
            "    hidden_states = layer(hidden_states=hidden_states, **kwargs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRM/models/hrm/hrm_act_v1.py\", line 80, in forward\n",
            "    hidden_states = rms_norm(hidden_states + self.self_attn(cos_sin=cos_sin, hidden_states=hidden_states), variance_epsilon=self.norm_eps)\n",
            "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/HRM/models/layers.py\", line 130, in forward\n",
            "    attn_output = flash_attn_func(q=query, k=key, v=value, causal=self.causal)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 1196, in flash_attn_func\n",
            "    return FlashAttnFunc.apply(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 834, in forward\n",
            "    out_padded, softmax_lse, S_dmask, rng_state = _wrapped_flash_attn_forward(\n",
            "                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_ops.py\", line 1158, in __call__\n",
            "    return self._op(*args, **(kwargs or {}))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_library/autograd.py\", line 113, in autograd_impl\n",
            "    result = forward_no_grad(*args, Metadata(keyset, keyword_only_args))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_library/autograd.py\", line 40, in forward_no_grad\n",
            "    result = op.redispatch(keyset & _C._after_autograd_keyset, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_ops.py\", line 761, in redispatch\n",
            "    return self._handle.redispatch_boxed(keyset, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_library/custom_ops.py\", line 335, in backend_impl\n",
            "    result = self._backend_fns[device_type](*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 51, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_library/custom_ops.py\", line 367, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 91, in _flash_attn_forward\n",
            "    out, softmax_lse, S_dmask, rng_state = flash_attn_gpu.fwd(\n",
            "                                           ^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: FlashAttention only supports Ampere GPUs or newer.\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "\r  0%|          | 0/10416 [01:14<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'cd /content/HRM\\npython pretrain.py \\\\\\n  data_path=data/sudoku-extreme-1k-aug-1000 \\\\\\n  epochs=2000 \\\\\\n  eval_interval=500 \\\\\\n  global_batch_size=192 \\\\\\n  lr=7e-5 \\\\\\n  puzzle_emb_lr=7e-5 \\\\\\n  weight_decay=1.0 \\\\\\n  puzzle_emb_weight_decay=1.0\\n'' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3122803420.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cd /content/HRM\\npython pretrain.py \\\\\\n  data_path=data/sudoku-extreme-1k-aug-1000 \\\\\\n  epochs=2000 \\\\\\n  eval_interval=500 \\\\\\n  global_batch_size=192 \\\\\\n  lr=7e-5 \\\\\\n  puzzle_emb_lr=7e-5 \\\\\\n  weight_decay=1.0 \\\\\\n  puzzle_emb_weight_decay=1.0\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'cd /content/HRM\\npython pretrain.py \\\\\\n  data_path=data/sudoku-extreme-1k-aug-1000 \\\\\\n  epochs=2000 \\\\\\n  eval_interval=500 \\\\\\n  global_batch_size=192 \\\\\\n  lr=7e-5 \\\\\\n  puzzle_emb_lr=7e-5 \\\\\\n  weight_decay=1.0 \\\\\\n  puzzle_emb_weight_decay=1.0\\n'' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVx4GmjPz36S"
      },
      "source": [
        "## 6Ô∏è‚É£ Evaluate\n",
        "After training finishes (~step 1500) we run the built-in exact-accuracy evaluator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua4P29zbz36S"
      },
      "outputs": [],
      "source": [
        "#@title 6Ô∏è‚É£ Evaluate last checkpoint\n",
        "ckpt_path = !ls -t checkpoints/*/ckpt.pt | head -1\n",
        "ckpt_path = ckpt_path[0]\n",
        "print(\"Evaluating\", ckpt_path)\n",
        "run(f\"python evaluate.py checkpoint={ckpt_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgzl9l-0z36S"
      },
      "source": [
        "## 7Ô∏è‚É£ Show one solved grid\n",
        "We decode the first validation sample back to a human-readable Sudoku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A43PzIFmz36S"
      },
      "outputs": [],
      "source": [
        "#@title 7Ô∏è‚É£ Pretty print a solved puzzle\n",
        "from src.utils.sudoku import Sudoku\n",
        "import torch\n",
        "\n",
        "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "model = ckpt[\"model\"]\n",
        "model.eval()\n",
        "\n",
        "from src.data.sudoku_dataset import SudokuDataset\n",
        "ds = SudokuDataset(\"data/sudoku-extreme-1k-aug-1000\", split=\"val\")\n",
        "sample = ds[0]\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(sample[\"input_ids\"].unsqueeze(0).cuda())\n",
        "pred = logits.argmax(-1).cpu()\n",
        "\n",
        "print(\"Input puzzle:\\n\", Sudoku(sample[\"input_ids\"].view(9,9)).grid)\n",
        "print(\"Model solution:\\n\", Sudoku(pred.view(9,9)).grid)\n",
        "print(\"Target:\\n\", Sudoku(sample[\"target\"].view(9,9)).grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bQkSFMDz36T"
      },
      "source": [
        "## 8Ô∏è‚É£ Save checkpoint to Drive (optional)\n",
        "Mount your Drive and copy the 120 MB checkpoint so others can load it instantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6LfsR7Hz36T"
      },
      "outputs": [],
      "source": [
        "#@title 8Ô∏è‚É£ Mount Drive & save\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/hrm_sudoku1k_t4\"\n",
        "run(f\"mkdir -p {save_dir}\")\n",
        "run(f\"cp -r checkpoints {save_dir}\")\n",
        "print(\"Checkpoint saved to\", save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fdf534d"
      },
      "source": [
        "# Task\n",
        "Explain the error in the selected code. If possible, fix the error and incorporate the changes into the existing code. Otherwise, try to diagnose the error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b038d49e"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial attempt to clone the repository failed because a directory with the same name already existed.\n",
        "*   The existing directory was successfully removed, allowing the repository to be cloned without initializing submodules.\n",
        "*   The `.gitmodules` file was read, and SSH URLs were successfully replaced with HTTPS URLs.\n",
        "*   The modified content of the `.gitmodules` file was written back to the file.\n",
        "*   The submodules were successfully initialized and updated using the modified configuration."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}